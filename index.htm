<!DOCTYPE html>
<!-- saved from url=(0029)http://www.biasinbiasout.com/ -->
<html data-wf-domain="www.biasinbiasout.com" data-wf-page="5ab6c98a1f3370fc9bd5dddb" data-wf-site="5ab6c98a1f33704c50d5ddda" class="w-mod-js wf-ubuntumono-n4-active wf-ubuntumono-i4-active wf-ubuntumono-n7-active wf-ubuntumono-i7-active wf-active"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8"><title>&lt;bias&gt;in&lt;bias&gt;out</title><meta content="For  6 days, a group of 12 professionals with diverse experiences worked together led by multidisciplinary designer Rogier Klomp in São Paulo. Our mission was to demystify algorithms showing they are as prone to bias and prejudice as we are. The outcome of this Mesa is this project, Bias in Bias out, which aims to raise awareness and inspire people on this matter." name="description"><meta content="width=device-width, initial-scale=1" name="viewport"><link href="./_bias_in_bias_out_files/howtobeatbias.webflow.b66e5a845.css" rel="stylesheet" type="text/css"><script src="./_bias_in_bias_out_files/webfont.js" type="text/javascript"></script><link rel="stylesheet" href="./_bias_in_bias_out_files/css"><script type="text/javascript">WebFont.load({  google: {    families: ["Ubuntu Mono:regular,italic,700,700italic"]  }});</script><!--[if lt IE 9]><script src="https://cdnjs.cloudflare.com/ajax/libs/html5shiv/3.7.3/html5shiv.min.js" type="text/javascript"></script><![endif]--><script type="text/javascript">!function(o,c){var n=c.documentElement,t=" w-mod-";n.className+=t+"js",("ontouchstart"in o||o.DocumentTouch&&c instanceof DocumentTouch)&&(n.className+=t+"touch")}(window,document);</script><link href="https://daks2k3a4ib2z.cloudfront.net/img/favicon.ico" rel="shortcut icon" type="image/x-icon"><link href="https://daks2k3a4ib2z.cloudfront.net/img/webclip.png" rel="apple-touch-icon"></head><body class="body"><div data-collapse="all" data-animation="over-left" data-duration="400" class="navbar-2 w-hidden-main w-hidden-medium w-hidden-small w-hidden-tiny w-nav"><div class="w-container"><nav role="navigation" class="w-nav-menu"><a href="http://www.biasinbiasout.com/#" class="w-nav-link" style="max-width: 940px;">Home</a><a href="http://www.biasinbiasout.com/#" class="w-nav-link" style="max-width: 940px;">About</a><a href="http://www.biasinbiasout.com/#" class="w-nav-link" style="max-width: 940px;">Contact</a></nav><div class="w-nav-button"><div class="w-icon-nav-menu"></div></div></div><div class="w-nav-overlay" data-wf-ignore=""></div></div><div data-collapse="all" data-animation="default" data-duration="350" data-doc-height="1" data-easing="ease-in-out" data-easing2="ease-in-out" class="navbar w-nav"><a href="http://www.biasinbiasout.com/#hero-section" class="link-block-2 w-inline-block w-clearfix w--current"><img src="./_bias_in_bias_out_files/5ab9b9dbba1936ab7e9afb6b_Logo_BRancopng.png" height="25" id="logo" alt="Logo Mesa&amp;Cadeira" class="image"><img src="./_bias_in_bias_out_files/5aba9539cd72e6265259e566_Logo_BRancopng-01.png" height="40" id="logo" alt="Logo Mesa&amp;Cadeira" class="image w-hidden-main w-hidden-medium w-hidden-small w-hidden-tiny"></a><div class="container-2 w-container"><nav role="navigation" class="nav-menu w-nav-menu"><a href="http://www.biasinbiasout.com/#Video-1" class="nav-link-3 w-nav-link" style="max-width: 940px;">Emoji</a><a href="http://www.biasinbiasout.com/#Video-2" class="nav-link-2 w-nav-link" style="max-width: 940px;">Hiring</a><a href="http://www.biasinbiasout.com/#Video-3" class="nav-link-2 w-nav-link" style="max-width: 940px;">Gender</a><a href="http://www.biasinbiasout.com/#manifesto" class="nav-link-2 manifestolink w-nav-link" style="max-width: 940px;">Our Manifesto</a><a href="http://www.biasinbiasout.com/#Video-4" class="nav-link-2 w-nav-link" style="max-width: 940px;">Love</a><a href="http://www.biasinbiasout.com/#Video-5" class="nav-link-2 w-nav-link" style="max-width: 940px;">Lying</a><a href="http://www.biasinbiasout.com/#footer" class="nav-link-2 manifestolink w-nav-link" style="max-width: 940px;">Mission and Team</a></nav><div class="menu-button w-nav-button"><div class="icon w-icon-nav-menu"></div></div></div><div class="w-nav-overlay" data-wf-ignore=""></div></div><section id="hero-section" class="section hero"><a href="http://www.biasinbiasout.com/#Video-1" class="button next-video w-button" data-ix="slidesintoview-2" style="transition: all 0.2s ease-in-out 0s, opacity 250ms, transform 200ms; opacity: 1; transform: translateX(0px) translateY(0px) translateZ(0px);">↓</a><div class="container-9 w-container"></div></section><div id="Video-1" class="section video"><div class="container-3 w-container"><h1 class="heading w-hidden-main w-hidden-medium w-hidden-small w-hidden-tiny" data-ix="fades-into-view" style="opacity: 0;">Algorithms are tools that predict <strong class="bold-text">success.</strong></h1><div style="padding-top: 56.2766%; opacity: 0;" class="video-2 w-video w-embed" data-ix="fades-into-view"><iframe class="embedly-embed" src="./_bias_in_bias_out_files/media.html" scrolling="no" frameborder="0" allowfullscreen=""></iframe></div></div></div><div id="Video-2" class="section video"><div class="container-4 w-container"><h1 class="heading w-hidden-main w-hidden-medium w-hidden-small w-hidden-tiny" data-ix="fades-into-view" style="opacity: 0;">Algorithms learn from us.<br>Let's be <strong class="bold-text">good teachers.</strong></h1><div style="padding-top: 56.2766%; opacity: 0;" class="video-2 w-video w-embed" data-ix="fades-into-view"><iframe class="embedly-embed" src="./_bias_in_bias_out_files/media(1).html" scrolling="no" frameborder="0" allowfullscreen=""></iframe></div></div></div><div id="Video-3" class="section video"><div class="container-5 w-hidden-main w-hidden-medium w-hidden-small w-hidden-tiny w-container"><h1 class="heading w-hidden-main w-hidden-medium w-hidden-small w-hidden-tiny" data-ix="fades-into-view" style="opacity: 0;">Algorithms are decision processes embedded in <strong class="bold-text">code.</strong></h1><div style="padding-top: 56.2766%; opacity: 0;" class="video-2 w-video w-embed" data-ix="fades-into-view"><iframe class="embedly-embed" src="./_bias_in_bias_out_files/media(2).html" scrolling="no" frameborder="0" allowfullscreen=""></iframe></div></div><div class="container-4 w-container"><h1 class="heading w-hidden-main w-hidden-medium w-hidden-small w-hidden-tiny" data-ix="fades-into-view" style="opacity: 0;">Algorithms learn from us.<br>Let's be <strong class="bold-text">good teachers.</strong></h1><div style="padding-top: 56.2766%; opacity: 0;" class="video-2 w-video w-embed" data-ix="fades-into-view"><iframe class="embedly-embed" src="./_bias_in_bias_out_files/media(3).html" scrolling="no" frameborder="0" allowfullscreen=""></iframe></div></div></div><section id="manifesto" class="footer manifesto"><div class="container-8 w-container"><h1 class="heading-3">if machines are learning, who is teaching them?</h1><div class="row-3 w-row"><div class="w-col w-col-6"><p class="paragraph-3 manifesto">Algorithms are pure math. A decision process in the form of a code.
A series of experiences are used as inputs. When exposed to a situation or a problem they react in a certain way producing an output.

In that sense, algorithms are just like us.
We make decisions everyday based on our observations and interpretations, influenced by our interactions and experiences.

Even though we don’t realize it, we feed technology with data. And that data helps technology shape the decisions it makes and the actions it takes.&nbsp;That’s the paradigm of our artificial intelligent world: we are biased algorithms, teaching and creating biased algorithms.</p></div><div class="w-col w-col-6"><p class="paragraph-3 manifesto">By believing technology is something inaccessible, outsourced and unreachable, we forget our responsibility. Algorithms are just numerical representation of who we are as a society. The project &nbsp;IN &nbsp;OUT wants to raise awareness to an urgent issue: we have responsibility on the consequences of our bias that are now embedded in machines. The more we learn how to teach them, the better will be the creation of a future. If the algorithm is a mirror, we have to take action on what we are reflecting.</p></div></div></div><div class="container-8 w-container"><h1 class="heading-3 ptbr">se as máquinas estão aprendendo, quem está ensinando?</h1><div class="row-3 w-row"><div class="w-col w-col-6"><p class="paragraph-3 manifesto">Se as máquinas estão aprendendo, quem está ensinando?Algoritmos são pura matemática. Eles são processos de decisão traduzidos na forma de um código. Uma série de experiências é usada como input e, quando exposta a uma situação ou a um problema, reage de uma certa maneira, produzindo um output.Nesse sentido, eles não são diferentes de nós. Nós também fazemos observações e interpretações – coletamos dados. Nós também tomamos decisões de acordo com nossas interações e experiências.Mesmo quando não percebemos, alimentamos tecnologia com dados. São os dados que permitem que as máquinas tomem decisões e realizem ações.</p></div><div class="w-col w-col-6"><p class="paragraph-3 manifesto">Esse é o paradigma de nosso mundo artificialmente inteligente: somos algoritmos enviesados criando e treinando outros algoritmos enviesados.Quando acreditamos que tecnologia é algo neutro e inacessível, esquecemos nossa responsabilidade.Algoritmos são representações numéricas do que queremos ser como sociedade.O objetivo do projeto&nbsp;IN&nbsp;OUT é chamar atenção para uma questão importante: nossa responsabilidade pelas consequências dos vieses que estamos embutindo nos códigos que controlam nossos sistemas. Quanto mais aprendermos sobre como ensinar as máquinas, melhor será a futuro. Um algoritmo é um espelho. Você é responsável pelo que ele reflete.</p></div></div></div></section><div id="Video-4" class="section video"><div class="container-6 w-container"><h1 class="heading w-hidden-main w-hidden-medium w-hidden-small w-hidden-tiny" data-ix="fades-into-view" style="opacity: 0;">Algorithms are <strong class="bold-text">opinions</strong> <br>camouflaged in <strong class="bold-text">tech.</strong></h1><div style="padding-top: 56.2766%; opacity: 0;" class="video-2 w-video w-embed" data-ix="fades-into-view"><iframe class="embedly-embed" src="./_bias_in_bias_out_files/media(4).html" scrolling="no" frameborder="0" allowfullscreen=""></iframe></div></div></div><div id="Video-5" class="section video"><div class="container-7 w-container"><h1 class="heading w-hidden-main w-hidden-medium w-hidden-small w-hidden-tiny" data-ix="fades-into-view" style="opacity: 0;">Algorithms are <strong class="bold-text">opinions</strong> <br>camouflaged in <strong class="bold-text">tech.</strong></h1><div style="padding-top:56.27659574468085%" class="video-2 w-video w-embed"><iframe class="embedly-embed" src="./_bias_in_bias_out_files/media(5).html" scrolling="no" frameborder="0" allowfullscreen=""></iframe></div></div></div><div id="footer" class="footer"><div class="w-container"><img src="./_bias_in_bias_out_files/5aba8d64d4eb8866578cc7fc_IntroScroll_5.gif" width="461" class="image-5"><p class="paragraph-3">For &nbsp;6 days, a group of 12 professionals with diverse experiences worked together led by multidisciplinary designer <strong class="bold-text-3">Rogier Klomp</strong> in São Paulo.</p><div style="padding-top:56.27659574468085%" class="video-2 w-video w-embed"><iframe class="embedly-embed" src="./_bias_in_bias_out_files/media(6).html" scrolling="no" frameborder="0" allowfullscreen=""></iframe></div><div class="row w-row"><div class="w-col w-col-4"><p class="paragraph-4">&lt;Our mission&gt;</p><p class="paragraph-3"><strong class="bold-text-2">To demystify algorithms showing they are as prone to bias and prejudice as we are.</strong> The outcome of this Mesa is this project, Bias in Bias out, which aims to raise awareness and inspire people on this matter.</p></div><div class="column w-col w-col-4"><p class="paragraph-4">&lt;Participants&gt;</p><p class="paragraph-3">Carol Leslie, Denis Burgierman, Fernanda Monteiro, Gil Bottari, João França, Hui Jin Park, Letícia Pozza, Lucas Terra, Luiz Braz, Michel Alcoforado, Renata Simões e Zé Porto.</p></div><div class="w-col w-col-4"><p class="paragraph-4">&lt;Mesa&amp;Cadeira Team&gt;</p><p class="paragraph-3">Valentina Ferrari, Juliana Cainelli and Giuliana Tatini.</p><p class="paragraph-4">&lt;Special thanks&gt;</p><p class="paragraph-3">Rafael Bueno, Felipe Griebel, Beza Doces, Red Bull, Aperol e Isla Espaço Híbrido.</p></div></div><div class="w-row"><div class="column-3 w-col w-col-6"><blockquote class="block-quote">"Algorithms are opinions camouflaged in technology"</blockquote><p class="source">— Cathy O'Neil</p></div><div class="column w-hidden-small w-hidden-tiny w-col w-col-2"></div><div class="w-hidden-small w-hidden-tiny w-clearfix w-col w-col-4"><img src="./_bias_in_bias_out_files/5ab91aa98d60350f42e94064_Asset 2@0.5x.png" width="228" srcset="http://uploads.webflow.com/5ab6c98a1f33704c50d5ddda/5ab91aa98d60350f42e94064_Asset%202%400.5x-p-500.png 500w, http://uploads.webflow.com/5ab6c98a1f33704c50d5ddda/5ab91aa98d60350f42e94064_Asset%202%400.5x.png 505w" sizes="(max-width: 767px) 100vw, (max-width: 991px) 28vw, 228px" class="image-2" data-ix="fades-into-view" style="opacity: 0;"></div></div></div></div><script src="./_bias_in_bias_out_files/jquery-3.3.1.min.js" type="text/javascript" intergrity="sha256-FgpCb/KJQlLNfOu91ta32o/NMZxltwRo8QtmkMRdAu8=" crossorigin="anonymous"></script><script src="./_bias_in_bias_out_files/webflow.befca1022.js" type="text/javascript"></script><!--[if lte IE 9]><script src="//cdnjs.cloudflare.com/ajax/libs/placeholders/3.0.2/placeholders.min.js"></script><![endif]-->
</body></html>